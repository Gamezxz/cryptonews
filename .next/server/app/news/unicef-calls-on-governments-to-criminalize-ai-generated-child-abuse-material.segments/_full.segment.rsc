1:"$Sreact.fragment"
2:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"default"]
3:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"default"]
4:I[18614,["/_next/static/chunks/afdae5d3acfa0395.js"],"default"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"ViewportBoundary"]
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"MetadataBoundary"]
d:I[68027,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"default"]
:HL["/_next/static/chunks/fc2ee5b570826792.css","style"]
:HL["/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"uzlIAM-Kl1QSfe8HswO3i","c":["","news","unicef-calls-on-governments-to-criminalize-ai-generated-child-abuse-material",""],"q":"","i":false,"f":[[["",{"children":["news",{"children":[["slug","unicef-calls-on-governments-to-criminalize-ai-generated-child-abuse-material","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/fc2ee5b570826792.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/afdae5d3acfa0395.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"jetbrains_mono_36655262-module__VMPiKa__variable space_grotesk_79c48eee-module__K0IjJG__variable","children":["$","body",null,{"children":[["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","$L4",null,{}]]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",[["$","script","script-0",{"src":"/_next/static/chunks/51c24a2fbd7d9b59.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$La"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$Lc"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$d",[]],"S":true}
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
c:[["$","title","0",{"children":"UNICEF เรียกร้องให้รัฐบาลกำหนดให้สื่อล่วงละเมิดเด็กที่สร้างโดย AI เป็นความผิดทางอาญา | Cryptonews"}],["$","meta","1",{"name":"description","content":"UNICEF ได้เรียกร้องให้รัฐบาลทั่วโลกดำเนินคดีอาญาต่อวัสดุล่วงละเมิดเด็กที่สร้างด้วย AI (CSAM) อย่างเร่งด่วน โดยอ้างถึงข้อมูลวิจัยที่ระบุว่ามีเด็กกว่า 1.2 ล้านคนใน 11 ประเทศที่ภาพถูกดัดแปลงเป็น Deepfake ทางเพศในปีที่ผ่านมา องค์กรนี้เน้นย้ำว่าผู้กระทำผิดสามารถสร้างภาพอนาจารที่สมจริงได้โดยไม่ต้องมีส่วนร่วมของเด็ก และการล่วงละเมิดในรูปแบบ Deepfake นั้นก่อให้เกิดความเสียหายที่แท้จริง เพื่อแก้ไขความเสี่ยงที่เพิ่มขึ้นนี้ UNICEF สนับสนุนให้ขยายความหมายทางกฎหมายของ CSAM ให้ครอบคลุมถึงเนื้อหาที่สร้างโดย AI และเรียกร้องให้ผู้พัฒนานำมาตรการ \"ปลอดภัยตั้งแต่การออกแบบ\" (safety-by-design) มาใช้ การเรียกร้องนี้เกิดขึ้นหลังจากหน่วยงานกำกับดูแลดำเนินการทางกฎหมายกับแพลตฟอร์มอย่าง X และ Grok ซึ่งประสบปัญหาการสอบสวนและการห้ามใช้งานในหลายประเทศเนื่องจากการสร้างเนื้อหาผิดกฎหมาย"}]]
e:I[22016,["/_next/static/chunks/afdae5d3acfa0395.js","/_next/static/chunks/51c24a2fbd7d9b59.js"],""]
f:I[90693,["/_next/static/chunks/afdae5d3acfa0395.js","/_next/static/chunks/51c24a2fbd7d9b59.js"],"default"]
10:Tf51,In brief UNICEF's research estimates 1.2 million children had images manipulated into sexual deepfakes last year across 11 surveyed countries. Regulators have stepped up action against AI platforms, with probes, bans, and criminal investigations tied to alleged illegal content generation. The agency urged tighter laws and “safety-by-design” rules for AI developers, including mandatory child-rights impact checks. UNICEF issued an urgent call Wednesday for governments to criminalize AI-generated child sexual abuse material, citing alarming evidence that at least 1.2 million children worldwide had their images manipulated into sexually explicit deepfakes in the past year. The figures, revealed in Disrupting Harm Phase 2, a research project led by UNICEF's Office of Strategy and Evidence Innocenti, ECPAT International, and INTERPOL, show in some nations the figure represents one in 25 children, the equivalent of one child in a typical classroom, according to a Wednesday statement and accompanying issue brief . The research, based on a nationally representative household survey of approximately 11,000 children across 11 countries, highlights how perpetrators can now create realistic sexual images of a child without their involvement or awareness. In some study countries, up to two-thirds said they worry AI could be used to create fake sexual images or videos of them, though levels of concern vary widely between countries, according to the data. "We must be clear. Sexualised images of children generated or manipulated using AI tools are child sexual abuse material (CSAM)," UNICEF said. "Deepfake abuse is abuse, and there is nothing fake about the harm it causes." The call gains urgency as French authorities raided X's Paris offices on Tuesday as part of a criminal investigation into alleged child pornography linked to the platform's AI chatbot Grok, with prosecutors summoning Elon Musk and several executives for questioning. A Center for Countering Digital Hate report released last month estimated Grok produced 23,338 sexualized images of children over an 11-day period between December 29 and January 9. The issue brief released alongside the statement notes these developments mark "a profound escalation of the risks children face in the digital environment," where a child can have their right to protection violated "without ever sending a message or even knowing it has happened." The UK’s Internet Watch Foundation flagged nearly 14,000 suspected AI-generated images on a single dark-web forum in one month, about a third confirmed as criminal, while South Korean authorities reported a tenfold surge in AI and deepfake-linked sexual offenses between 2022 and 2024, with most suspects identified as teenagers. The organization urgently called on all governments to expand definitions of child sexual abuse material to include AI-generated content and criminalize its creation, procurement, possession, and distribution. UNICEF also demanded that AI developers implement safety-by-design approaches and that digital companies prevent the circulation of such material. The brief calls for states to require companies to conduct child rights due diligence, particularly child rights impact assessments, and for every actor in the AI value chain to embed safety measures, including pre-release safety testing for open-source models. "The harm from deepfake abuse is real and urgent," UNICEF warned. "Children cannot wait for the law to catch up." The European Commission launched a formal investigation last month into whether X violated EU digital rules by failing to prevent Grok from generating illegal content, while the Philippines , Indonesia, and Malaysia have banned Grok, and regulators in the UK and Australia have also opened investigations. Daily Debrief Newsletter Start every day with the top news stories right now, plus original features, a podcast, videos and more.5:[["$","header",null,{"className":"site-header","children":["$","div",null,{"className":"container","children":["$","div",null,{"className":"header-inner","children":[["$","$Le",null,{"href":"/","className":"header-brand","children":[["$","div",null,{"className":"header-logo","children":"C"}],["$","div",null,{"className":"header-text","children":[["$","h1",null,{"children":["Cryptonews",["$","span",null,{"children":".in.th"}]]}],["$","p",null,{"children":"Crypto Intelligence Aggregator"}]]}]]}],["$","div",null,{"className":"header-status","children":[["$","span",null,{"className":"status-dot"}],["$","span",null,{"children":"Live Feed Active"}]]}]]}]}]}],["$","$Lf",null,{"article":{"_id":"69853aba38f2116917acb661","guid":"https://decrypt.co/?p=357029","__v":0,"author":"Vismaya V","categories":["regulation"],"category":"regulation","content":"UNICEF has pressed governments to criminalize AI-generated child sexual abuse material, warning deepfakes are exposing children to serious harm beyond existing laws.","createdAt":"2026-02-06T00:50:02.117Z","enclosure":"https://img.decrypt.co/insecure/rs:fill:1024:512:1:0/plain/https://cdn.decrypt.co/wp-content/uploads/2026/02/UNICEF-gID_7.jpg@png","fetchedAt":"2026-02-06T00:50:02.117Z","link":"https://decrypt.co/357029/unicef-criminalise-ai-generated-child-sexual-abuse-material","pubDate":"2026-02-05T05:01:58.000Z","source":"Decrypt","sourceCategory":"general","summary":"UNICEF ร้องขอให้รัฐบาลทั่วโลกก","title":"UNICEF Calls on Governments to Criminalize AI-Generated Child Abuse Material","updatedAt":"2026-02-07T06:01:07.796Z","sentiment":"neutral","translatedContent":"UNICEF ได้กดดันรัฐบาลให้กำหนดให้เนื้อหาการล่วงละเมิดทางเพศเด็กที่สร้างโดย AI เป็นความผิดทางอาญา เตือนว่า deepfakes กำลังทำให้เด็กต้องเผชิญกับอันตรายร้ายแรงนอกเหนือจากกฎหมายที่มีอยู่","translatedTitle":"UNICEF เรียกร้องให้รัฐบาลกำหนดให้สื่อล่วงละเมิดเด็กที่สร้างโดย AI เป็นความผิดทางอาญา","slug":"unicef-calls-on-governments-to-criminalize-ai-generated-child-abuse-material","aiSummary":"UNICEF has urgently called on governments to criminalize AI-generated child sexual abuse material (CSAM), citing research that 1.2 million children across 11 countries had their images manipulated into sexual deepfakes last year. The organization emphasizes that perpetrators can create realistic explicit content without a child's involvement and that deepfake abuse causes real harm. To address this escalation of risk, UNICEF advocates for expanding legal definitions of CSAM to include AI-generated content and demands that developers implement 'safety-by-design' measures. This call follows recent regulatory actions against platforms like X and Grok, which face investigations and bans in several countries for allegedly generating illegal content.","aiSummaryThai":"UNICEF ได้เรียกร้องให้รัฐบาลทั่วโลกดำเนินคดีอาญาต่อวัสดุล่วงละเมิดเด็กที่สร้างด้วย AI (CSAM) อย่างเร่งด่วน โดยอ้างถึงข้อมูลวิจัยที่ระบุว่ามีเด็กกว่า 1.2 ล้านคนใน 11 ประเทศที่ภาพถูกดัดแปลงเป็น Deepfake ทางเพศในปีที่ผ่านมา องค์กรนี้เน้นย้ำว่าผู้กระทำผิดสามารถสร้างภาพอนาจารที่สมจริงได้โดยไม่ต้องมีส่วนร่วมของเด็ก และการล่วงละเมิดในรูปแบบ Deepfake นั้นก่อให้เกิดความเสียหายที่แท้จริง เพื่อแก้ไขความเสี่ยงที่เพิ่มขึ้นนี้ UNICEF สนับสนุนให้ขยายความหมายทางกฎหมายของ CSAM ให้ครอบคลุมถึงเนื้อหาที่สร้างโดย AI และเรียกร้องให้ผู้พัฒนานำมาตรการ \"ปลอดภัยตั้งแต่การออกแบบ\" (safety-by-design) มาใช้ การเรียกร้องนี้เกิดขึ้นหลังจากหน่วยงานกำกับดูแลดำเนินการทางกฎหมายกับแพลตฟอร์มอย่าง X และ Grok ซึ่งประสบปัญหาการสอบสวนและการห้ามใช้งานในหลายประเทศเนื่องจากการสร้างเนื้อหาผิดกฎหมาย","fullContent":"$10","keyPoints":["UNICEF reports 1.2 million children affected by sexual deepfakes in 11 countries.","Urges governments to criminalize AI-generated CSAM and expand legal definitions.","Calls for 'safety-by-design' rules and child-rights impact checks for AI developers.","X and Grok face investigations and bans for allegedly generating illegal AI content."],"scrapingStatus":"scraped","wordCount":584},"relatedArticles":[{"_id":"6986d16c38f2116917d8b420","category":"bitcoin","pubDate":"2026-02-07T05:30:00.000Z","slug":"xrp-still-in-bull-market-versus-bitcoin-and-xrpbtc-chart-puts-51-upside-on-the-m","source":"U.Today","title":"XRP Still in Bull Market Versus Bitcoin, and XRP/BTC Chart Puts 51% Upside on the Menu","translatedTitle":"XRP ยังอยู่ในตลาดเพชรฟองต่อบิทคอยน์ และแผนภูมิ XRP/BTC มีศักยภาพเพิ่มขึ้น 51%"},{"_id":"6986ccbc38f2116917d8608a","category":"regulation","pubDate":"2026-02-07T05:24:24.000Z","slug":"ondo-price-prediction-2026-2027-2030-can-ondo-hit-10","source":"Coinpedia","title":"Ondo Price Prediction 2026, 2027 – 2030: Can Ondo Hit $10?","translatedTitle":"การคาดการณ์ราคาโอนโด ปี 2026, 2027 – 2030: โอนโดสามารถถึง $10 ได้ไหม?"},{"_id":"6986ca6638f2116917d84b63","category":"regulation","pubDate":"2026-02-07T05:10:53.000Z","slug":"hedera-price-prediction-2026-2027-2030-will-hbar-price-hit-05","source":"Coinpedia","title":"Hedera Price Prediction 2026, 2027 – 2030: Will HBAR Price Hit $0.5?","translatedTitle":"การคาดการณ์ราคา Hedera ปี 2026, 2027 - 2030: ราคา HBAR จะสามารถถึง $0.5 ได้ไหม"},{"_id":"6986ca6638f2116917d84b60","category":"regulation","pubDate":"2026-02-07T05:05:20.000Z","slug":"how-low-can-pi-networks-pi-go-shocking-bear-market-ai-scenarios-after-the-latest","source":"CryptoPotato","title":"How Low Can Pi Network’s PI Go? Shocking Bear-Market AI Scenarios After the Latest ATLs","translatedTitle":"ราคา Pi Network จะต่ำลงได้ถึงเท่าไหร่? สถานการณ์ AI ในแนวหมีหลังจาก ATL ล่าสุด"}]}],"$L11"]
11:["$","footer",null,{"className":"site-footer","children":["$","div",null,{"className":"container","children":["$","div",null,{"className":"footer-inner","children":[["$","div",null,{"className":"footer-text","children":[["$","span",null,{"children":"Cryptonews.in.th"}]," // Crypto Intelligence Feed"]}],["$","div",null,{"className":"footer-meta","children":"22+ Sources · Auto-Updated"}]]}]}]}]
